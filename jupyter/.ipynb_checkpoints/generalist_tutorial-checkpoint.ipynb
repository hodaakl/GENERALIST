{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fb8cc9-5622-46c9-b3be-1fefc1f0e141",
   "metadata": {},
   "source": [
    "# Welcome to GENERALIST tutorial jupyter notebook! \n",
    "GENERALIST is a generative model for categorical data. We apply it to protein sequences (21 categories, 20 amino acids + gap), to obtain new sequences. \n",
    "We assess the quality of this model through various tests like reproducablity of the statistics of the data and the Hamming distances. \n",
    "\n",
    "In this notebook we will use fasta file for P53 present in this repo, you can swap that for any other fasta file. \n",
    "\n",
    "We will:\n",
    "- P53 fasta file ==>`` '../data/msa_p53_unimsa.fa'`` \n",
    "- obtain generated sequences \n",
    "- run tests on those sequences \n",
    "\n",
    "When changing data from string (amino acid letters) to numerical form, we use the correspondance ``AA_Letters = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-' ]`` ==> [0,1,2,....,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcb422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from compile_generalist_fn import generalist\n",
    "from data_process_fns import Convert_fastaToNp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b62d0-8590-4954-aeb1-f12f6e85ffa9",
   "metadata": {},
   "source": [
    "To run generalist we need to one hot encode the msa. The function ``Convert_fastaToNp`` takes in a fasta file and gets a 3-D binary matrix of shape ==> [Number of categories (21), Number of sequences, Number of positions in a sequence ]. \n",
    "\n",
    "\n",
    "\n",
    "If you are working with another type of categorical you can one hot encode your data to be of the shape ==> [Number of categories , Number of samples , Number of features] and run GENERALIST on that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6fe420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one hot encoded data is (21, 785, 341)\n"
     ]
    }
   ],
   "source": [
    "FastaFilePath  = '../data/msa_p53_unimsa.fa' # file path of the fasta file \n",
    "# If the MSA file has sequences without labels (no > label line )\n",
    "# before the sequence, then set labels_inc =False \n",
    "data_one_hot = Convert_fastaToNp(filepath = FastaFilePath, binary = True, labels_inc =True)\n",
    "print(f'Shape of one hot encoded data is {data_one_hot.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f30fe8-6c67-4c89-8de7-a832f003d7e5",
   "metadata": {},
   "source": [
    "## Run the inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1148b5-008a-4a89-a720-c845e053af96",
   "metadata": {},
   "source": [
    "the function ``generalist`` runs the inference and saves parameters $z$ and $\\theta$ in the output directory specified in the next cell. The parameters are saved as torch and numpy tensors. \n",
    "In the training the model learns the probabilities of having any category/amino acid $a$ in any position $l$ in any specific sample $n$\n",
    "$$\\pi_{anl} = \\frac{\\exp(- \\sum_k z_{nk} \\theta_{akl})}{\\Omega_{nl}}$$\n",
    "\n",
    "$K$ is the latent dimension for the model, and is specified by the user. \n",
    "\n",
    "``generalist`` uses GPU is available for computation, if not it will use CPU. If GPU is available but you want to run using CPU specify the ``generalist`` argument ``use_gpu_if_avail = False``. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50917916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on cpu\n",
      "one hot encoded data of size (21, 785, 341)\n",
      "wrote details file\n",
      "started inference..\n",
      "takes 0.09793877601623535 seconds for the first step\n",
      "Inference is over\n",
      "step takes 0.09830689430236816 seconds \n",
      "Saved files for k = 7\n",
      "wrote details file\n",
      "Updated details files\n",
      "inference done in 0.0016384482383728026 minutes for k = 7\n",
      "output files at directory ../p53_output_k7/\n"
     ]
    }
   ],
   "source": [
    "k= 7 # the latent dimension\n",
    "output_directory = f'../p53_output_k{k}/' # the output directory where the parameters will be saved \n",
    "#This function should detect a gpu if available, otherwise runs on cpu, if GPU is available but you want to run on CPU set use_gpu_if_avail = False \n",
    "generalist(sigmas = data_one_hot, k = k, out_dir = output_directory) # \n",
    "# parameters are saved in the directory output_directory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74552918-fcfa-4587-9e2b-c4a032af4db7",
   "metadata": {},
   "source": [
    "## Generate data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b96107-257d-4d10-a821-2102c6afceea",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can use the learned probabilies to generate new sequences/samples. The ``Generator`` class uses the output directory where the parameters $z$ and $\\theta$ and the latent dimension K defined before to load the files. \n",
    "\n",
    "The method ``GenData`` uses those parameters loaded in ``Generator`` object to sample from the probabilities. This method generates sequences in Numerical form [0..20] by default,  or one-hot-encoded if the method argument ``output_binary = True``. \n",
    "\n",
    "``GenData`` samples with replacement from the inferred $z$ values, saved in the output directory, and uses the sampled $z$s along with $\\theta$ to get sequence probabilities $/pi$ and  generate new sequences, if sampled $z$, $\\theta$ or $pi$ are needed then set the argument ``output_params=True``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f684cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 341)\n"
     ]
    }
   ],
   "source": [
    "from loader_class import Generator\n",
    "import numpy as np \n",
    "ngen = 1000 #number of sequences generated \n",
    "Gen_obj = Generator(output_directory, k = k) # define the object \n",
    "generated_data = Gen_obj.GenData(ngen) #, output_binary = False\n",
    "print(generated_data.shape)\n",
    "# if the parameters Z and Theta are wanted \n",
    "# generated_data, z, theta, pi = Gen_obj.GenData(ngen,output_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1989b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the generated dataset as numpy matrix \n",
    "file_name = f'generated_data.npy'\n",
    "output_fn = f'{output_directory}{file_name}'\n",
    "np.save(output_fn, generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b5bfc6-e882-49f5-ac03-0e3d76bb0321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with save = True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'---MSQSTQTSEFLSPEVFQHIWDFLEQSMDCIRMQDSELSDPQYTNLGLLNSMDQQIQNGSSSTSPYNTDHAQNSVTAPSPYAQPSSTALSPSPAIPSNTDYPGPHSFDVSFQQSSTAKSATWTYSTELKKLYCQIAKTCPIQIKVMTPPPQGAVIRAMPVYKKAEHVTEVVKRCPNHELSRENEGIAPPSHLIRVEGNSHAQYVEDPITGRQSVLVPYEPPQVGTEFTTILYNFMCNSSCVGGMNRRPILIIVTLETRDGQVLGRRCFEARICACPGRDRKADEDSIRKQQVSDST-KNDDAFRQNTHGIQMTSIKKRRSPDEELLYLPVRGRETY---\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to save the generated data as fasta file -- the output of this function is the last saved sequence \n",
    "from data_process_fns import Conv_save_NpToFasta\n",
    "Conv_save_NpToFasta(generated_data, path= output_directory + f'generated_set_k{k}.fa',  label = 'generated_seq', verbose = True , save = True, include_fish_sym = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32ff0b-a8e9-42ba-b4d5-cb46d2111fa6",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b91d54-2cd5-405b-b4b9-f94363624dbd",
   "metadata": {},
   "source": [
    "### The statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f293809-8908-4f4e-9b0d-b37a84358342",
   "metadata": {},
   "source": [
    "### Hamming distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e460a-b192-4c05-8491-9d28bded21af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
